{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import codecs\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter, defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS_FILENAME = 'pap/stopwords1.txt'\n",
    "\n",
    "stopwords = set([line.strip() for line in codecs.open(STOPWORDS_FILENAME, encoding='utf-8').readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    return re.compile(r'[\\W\\d]+', re.UNICODE).sub(' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_whitespace(text):\n",
    "    return re.compile(r'[\\s\\n]+', re.UNICODE).sub(' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "    corpus = corpus.strip().lower()\n",
    "    corpus = remove_special_chars(corpus)\n",
    "    corpus = remove_whitespace(corpus)\n",
    "    words = corpus.split()\n",
    "    return remove_stopwords(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jesień\n",
      "japonii\n",
      "przepiękna\n"
     ]
    }
   ],
   "source": [
    "text = u'Jesień w 2017 Japonii jest przepiękna.'\n",
    "for word in preprocess_corpus(text):\n",
    "    print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CORPUS_PAP = 'pap/pap10000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(CORPUS_PAP, encoding='utf-8') as f:\n",
    "    corpus = f.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the corpus with only relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess_corpus(corpus) \n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = len(words) #number of words in corpus\n",
    "# denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count words frequency in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = Counter(words)\n",
    "# word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency['rocznicy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the frequency of pair words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_pairs(words, offset):\n",
    "    d = Counter()\n",
    "    for word in words:\n",
    "        index = words.index(word);\n",
    "        if(index < len(words) - offset):\n",
    "            for i in range(index, index+offset):\n",
    "                pair = (word, words[i+1])\n",
    "                if(d[(words[i+1], word)] > 0):\n",
    "                    pair = (words[i+1], word)\n",
    "                d[pair] += 1\n",
    "#                 print i, pair\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_frequency = count_pairs(words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_frequency[('pomnikiem', 'premiera')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the pairs according to their frequency in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'proc', u'uzgodniona'), 340),\n",
       " ((u'proc', u'prognoza'), 340),\n",
       " ((u'proc', u'pkb'), 340),\n",
       " ((u'proc', u'ekonomiczna'), 340),\n",
       " ((u'proc', u'r'), 340),\n",
       " ((u'powiedzia\\u0142', u'rz\\u0105du'), 183),\n",
       " ((u'powiedzia\\u0142', u'potrzeb\\u0119'), 183),\n",
       " ((u'powiedzia\\u0142', u'argumenty'), 183),\n",
       " ((u'powiedzia\\u0142', u'uzasadniaj\\u0105ce'), 183),\n",
       " ((u'powiedzia\\u0142', u'przyj\\u0119cia'), 183),\n",
       " ((u'wobec', u'\\u015brod\\u0119'), 166),\n",
       " ((u'aws', u'komisji'), 135),\n",
       " ((u'aws', u'ugrupowania'), 135),\n",
       " ((u'aws', u'czele'), 135),\n",
       " ((u'aws', u'pose\\u0142'), 135),\n",
       " ((u'aws', u'stan\\u0105\\u0142'), 135),\n",
       " ((u'sa', u'ag'), 130),\n",
       " ((u'sa', u'kwa\\u015bniewski'), 130),\n",
       " ((u'sa', u'chcia\\u0142by'), 130),\n",
       " ((u'sa', u'deutsche'), 130)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_frequency.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find associations's frequency for given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_associations(pairs, word):\n",
    "    counter = Counter()\n",
    "    for pair in pairs.most_common():\n",
    "        if (word == pair[0][0]):\n",
    "            counter[pair[0][1]] = pair[1]\n",
    "        if (word == pair[0][1]):\n",
    "            counter[pair[0][0]] = pair[1]\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ba\\u0142tyku', 28),\n",
       " (u'srebrnego', 28),\n",
       " (u'buzka', 28),\n",
       " (u'jerzego', 28),\n",
       " (u'pier\\u015bcienia', 28),\n",
       " (u'nadal', 25),\n",
       " (u'wschodzie', 19),\n",
       " (u'odpowiedzi', 7),\n",
       " (u'politycznej', 6),\n",
       " (u'odby\\u0142o', 6),\n",
       " (u'krajowej', 6),\n",
       " (u'swym', 5),\n",
       " (u'stanis\\u0142awa', 5),\n",
       " (u'firmie', 3),\n",
       " (u'min', 3),\n",
       " (u'domaga\\u0142o', 2),\n",
       " (u'odwo\\u0142any', 2),\n",
       " (u'poleg\\u0142ym', 2),\n",
       " (u'dzia\\u0142acza', 2),\n",
       " (u'potwierdzaj\\u0105', 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_associations(pairs_frequency, \"premiera\").most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the associantion's strenght for given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_strenght(pairs, word, alpha = 0.66, beta = 0.00002, gamma = 0.00002):\n",
    "    strenght_counter = Counter()\n",
    "    for pair in pairs.most_common():\n",
    "        if (word == pair[0][0]):\n",
    "            association = pair[0][1]\n",
    "        elif(word == pair[0][1]):\n",
    "            association = pair[0][0]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        assoc_freq = word_frequency[association]\n",
    "        pair_freq = pair[1]\n",
    "        if (assoc_freq > beta * denominator):\n",
    "            strenght = pair_freq / pow(assoc_freq, alpha)\n",
    "        else:\n",
    "            strenght = pair_freq / (gamma * denominator)\n",
    "        \n",
    "        strenght_counter[association] = strenght;\n",
    "        \n",
    "    return strenght_counter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'zas\\u0142ugi', 16.421932490587253),\n",
       " (u'mazowiecki', 14.173060920121547),\n",
       " (u'tadeusz', 9.615764101927157),\n",
       " (u'rozwoju', 6.085608409038503),\n",
       " (u'otrzyma\\u0142', 5.330707920630837),\n",
       " (u'europejskiej', 3.9536429948886784),\n",
       " (u'brytyjski', 2.110777485788888),\n",
       " (u'm\\xf3g\\u0142', 1.93790879445964),\n",
       " (u'polityczn\\u0105', 1.8389563682479446),\n",
       " (u'city', 1.6021397551792442)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_strenght(pairs_frequency, 'premier').most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zasługi 16.4219324906\n",
      "mazowiecki 14.1730609201\n",
      "tadeusz 9.61576410193\n",
      "rozwoju 6.08560840904\n",
      "otrzymał 5.33070792063\n",
      "europejskiej 3.95364299489\n",
      "brytyjski 2.11077748579\n",
      "mógł 1.93790879446\n",
      "polityczną 1.83895636825\n",
      "city 1.60213975518\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'premier').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc 7.25609285689\n",
      "pkb 2.18776162395\n",
      "prognoza 1.45285150163\n",
      "uzgodniona 1.26575659397\n",
      "komisję 0.691368825372\n",
      "europejską 0.41087604671\n",
      "rząd 0.13872431561\n",
      "polski 0.0826169935917\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'ekonomiczna').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "przeciwnym 34.8684360391\n",
      "kontynuować 34.8684360391\n",
      "wypadku 28.8385155932\n",
      "proces 18.2512706362\n",
      "reform 16.8862198863\n",
      "ue 3.64831437743\n",
      "cztery 2.67173052104\n",
      "polityki 2.56685179513\n",
      "politykę 2.2598182569\n",
      "udziału 2.18776162395\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'polska').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfi 12.6890174189\n",
      "zmienił 7.99903813253\n",
      "rynku 7.48409030294\n",
      "wzrósł 7.35020242673\n",
      "spadł 3.64831437743\n",
      "sesji 3.21412657691\n",
      "papierów 3.02754730954\n",
      "wartościowych 2.98744282935\n",
      "giełdy 2.9039388321\n",
      "akcji 2.11938308895\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'kurs').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dziedzictwa 43.668602492\n",
      "zakrzewski 43.668602492\n",
      "narodowego 19.1022438311\n",
      "kultury 11.0695483665\n",
      "andrzej 6.48170767161\n",
      "czwartek 4.06830190858\n",
      "powiedziała 2.67173052104\n",
      "zmarł 2.32767114913\n",
      "ministrów 2.2598182569\n",
      "później 2.18776162395\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'minister').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stosuje 21.0\n",
      "metodami 13.2904442367\n",
      "zgadzamy 10.1699605114\n",
      "kwietniu 2.02791895958\n",
      "problemy 1.93790879446\n",
      "dialogu 1.72842206343\n",
      "konfliktu 1.72842206343\n",
      "międzynarodowa 1.60213975518\n",
      "kaukazie 1.60213975518\n",
      "mołdawii 1.45285150163\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'rosja').most_common(10):\n",
    "     print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "przyjaciół 2.90570300326\n",
      "izraela 1.83895636825\n",
      "nazwał 1.60213975518\n",
      "najważniejszych 1.31265697437\n",
      "przekonani 1.26575659397\n",
      "mówił 1.103948053\n",
      "jednym 1.05125178647\n",
      "ehud 1.0\n",
      "deportowano 1.0\n",
      "celne 1.0\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'niemcy').most_common(10):\n",
    "    print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "przygotowaniu 8.0\n",
      "pokojowej 5.06302637588\n",
      "skarbu 2.76917370155\n",
      "rewolucji 2.76547530149\n",
      "środkowej 2.76547530149\n",
      "europie 1.87624665403\n",
      "uzasadnieniu 1.26575659397\n",
      "rolnej 1.26575659397\n",
      "medialnej 1.26575659397\n",
      "deputowani 1.0\n"
     ]
    }
   ],
   "source": [
    "for word in find_strenght(pairs_frequency, 'polityka').most_common(10):\n",
    "    print word[0],word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
